{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "from nuscenes.eval.common.data_classes import EvalBoxes\n",
    "from nuscenes.eval.detection.data_classes import DetectionBox \n",
    "from pyquaternion import Quaternion\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_file = '/home/mqdao/Downloads/nuScene/detection-megvii/centerPoint_test.json'\n",
    "data_root = '/home/mqdao/Downloads/nuScene/v1.0-test'\n",
    "version = 'v1.0-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-test...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "0 instance,\n",
      "12 sensor,\n",
      "1800 calibrated_sensor,\n",
      "462901 ego_pose,\n",
      "15 log,\n",
      "150 scene,\n",
      "6008 sample,\n",
      "462901 sample_data,\n",
      "0 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 4.2 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version=version, dataroot=data_root, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta:  {'use_camera': False, 'use_lidar': True, 'use_radar': False, 'use_map': False, 'use_external': False}\n",
      "Loaded results from /home/mqdao/Downloads/nuScene/detection-megvii/centerPoint_test.json. Found detections for 6008 samples.\n"
     ]
    }
   ],
   "source": [
    "# load detection\n",
    "with open(detection_file) as f:\n",
    "    data = json.load(f)\n",
    "all_results = EvalBoxes.deserialize(data['results'], DetectionBox)\n",
    "meta = data['meta']\n",
    "print('meta: ', meta)\n",
    "print(\"Loaded results from {}. Found detections for {} samples.\".format(\n",
    "    detection_file,\n",
    "    len(all_results.sample_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6008/6008 [00:00<00:00, 10269.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# get all scene tokens in validation set\n",
    "processed_scene_tokens = set()\n",
    "for sample_token_idx in tqdm(range(len(all_results.sample_tokens))):\n",
    "    sample_token = all_results.sample_tokens[sample_token_idx]\n",
    "    scene_token = nusc.get('sample', sample_token)['scene_token']\n",
    "    if scene_token in processed_scene_tokens:\n",
    "        continue\n",
    "    processed_scene_tokens.add(scene_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_scene_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUSCENES_TRACKING_NAMES = [\n",
    "  'bicycle',\n",
    "  'bus',\n",
    "  'car',\n",
    "  'motorcycle',\n",
    "  'pedestrian',\n",
    "  'trailer',\n",
    "  'truck'\n",
    "]\n",
    "score_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:08<00:00, 18.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# extract detection for each scene\n",
    "for scene_token in tqdm(processed_scene_tokens):\n",
    "    all_measurements = {}\n",
    "    all_classes = {}\n",
    "    current_time_step = 0\n",
    "    scene_record = nusc.get('scene', scene_token)\n",
    "    sample_token = scene_record['first_sample_token']\n",
    "    while sample_token != '':\n",
    "        sample_detections = [detection for detection in all_results.boxes[sample_token]\n",
    "                             if detection.detection_score > score_threshold]\n",
    "        all_measurements[current_time_step] = []\n",
    "        all_classes[current_time_step] = []\n",
    "        for detection in sample_detections:\n",
    "            # get obj_type\n",
    "            if detection.detection_name not in NUSCENES_TRACKING_NAMES:\n",
    "                continue\n",
    "            obj_type = detection.detection_name\n",
    "            # get object pose\n",
    "            x, y, z = detection.translation\n",
    "            quaternion = Quaternion(detection.rotation)\n",
    "            yaw = quaternion.angle if quaternion.axis[2] > 0 else -quaternion.angle \n",
    "            # get size\n",
    "            size = list(detection.size)\n",
    "            # get score\n",
    "            score = detection.detection_score\n",
    "            # store mearurement & class\n",
    "            all_measurements[current_time_step].append([x, y, yaw] + size + [z]+[score])\n",
    "            all_classes[current_time_step].append(obj_type)\n",
    "        \n",
    "        # move on to next sample\n",
    "        sample_token = nusc.get('sample', sample_token)['next']\n",
    "        current_time_step += 1\n",
    "    # save this scene detection in a separate file\n",
    "    outdata = {'all_measurements': all_measurements,\n",
    "               'all_classes': all_classes}\n",
    "    with open('../centerPoint-per-scene-detection/test/{}.json'.format(scene_token), 'w') as outfile:\n",
    "        json.dump(outdata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene_tokens = {}\n",
    "for i, scene_token in enumerate(processed_scene_tokens):\n",
    "    test_scene_tokens[i] = scene_token\n",
    "\n",
    "with open('../test_scene_tokens_centerPoint.json', 'w') as outfile:\n",
    "    json.dump(test_scene_tokens, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
